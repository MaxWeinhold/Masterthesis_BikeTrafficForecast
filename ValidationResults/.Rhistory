library(osmdata)
citation ("osmdata")
#The sf we will need to make geometrical calculations.
if(!require("sf")) install.packages("sf")
library(sf)
#Further we need to access tidyverse.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
city="Berlin"
Brandenburg_Gate=c(13.377336846520663,52.516264818429924)
#As second we build a query asking for traffic signals in Berlin.
q <- getbb(city) %>%
opq() %>%
add_osm_feature("highway", "traffic_signals")
#Read the osm data format as a list in R.
signals <- osmdata_sf(q)
#If you access signals:
signals
distances=c(1:length(signals$osm_points$osm_id))
for(i in 1:length(distances)){
distances[i]=distm(Brandenburg_Gate, c(signals$osm_points$geometry[[i]][1],signals$osm_points$geometry[[i]][2]), fun=distGeo)
}
#This is a script for a tutorial
#You can learn to get the coordinates of points of interested by collecting data via open street map.
#For that purpose we will use the osmdata package.
if(!require("osmdata")) install.packages("osmdata")
library(osmdata)
#Do not forget to give credit to the creators.
citation ("osmdata")
#The sf we will need to make geometrical calculations.
if(!require("sf")) install.packages("sf")
library(sf)
#Further we need to access tidyverse.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
if(!require("geosphere")) install.packages("geosphere")
library(geosphere)#package for calculating distance using longitude and latitude
citation ("osmdata")
#The sf we will need to make geometrical calculations.
if(!require("sf")) install.packages("sf")
library(sf)
#Further we need to access tidyverse.
if(!require("tidyverse")) install.packages("tidyverse")
library(tidyverse)
if(!require("geosphere")) install.packages("geosphere")
library(geosphere)#package for calculating distance using longitude and latitude
#First we determine which city we want to study.
city="Berlin"
#Or you use another data source.
Brandenburg_Gate=c(13.377336846520663,52.516264818429924)
q <- getbb(city) %>%
opq() %>%
add_osm_feature("highway", "traffic_signals")
signals <- osmdata_sf(q)
signals
signals$osm_points$geometry
distances=c(1:length(signals$osm_points$osm_id))
for(i in 1:length(distances)){
distances[i]=distm(Brandenburg_Gate, c(signals$osm_points$geometry[[i]][1],signals$osm_points$geometry[[i]][2]), fun=distGeo)
}
min(distances)
sum(distances < 1000)
q2 <- getbb(city) %>%
opq() %>%
add_osm_feature("highway", "primary")
primary <- osmdata_sf(q2)
#Since now we are handeling street, we are not longer interested in osm_points but osm_lines
Lines_primary = st_transform(primary$osm_lines$geometry,4269)
#We need to convert our point at Brandenburg Gate to another data format
POINT_Brandenburg_Gate = as.data.frame(rbind(Brandenburg_Gate))
names(POINT_Brandenburg_Gate)[1]="long1"
names(POINT_Brandenburg_Gate)[2]="lat1"
POINT_Brandenburg_Gate = st_as_sf(POINT_Brandenburg_Gate, coords = c("long1","lat1"))
POINT_Brandenburg_Gate <- st_set_crs(POINT_Brandenburg_Gate, 4269)
#now we can use the st_distance() function to calculate each distance from our Point to each line in our primary street network.
#The smallest distance is:
min(st_distance(POINT_Brandenburg_Gate$geometry, Lines_primary))
library(lubridate)
library(dplyr)
library(geosphere)#package for calculating distance using longitude and latitude
#Clean up memory
rm(list=ls())
#Source storage location (outside the GitHub Repository)
#Because of file size limitation
#files about 100 MB have to be excluded
#D:\STUDIUM\MÃ¼nster\7. Semester\Masterarbeit Daten\Bochum
setwd("D:/STUDIUM/MÃ¼nster/7. Semester/Masterarbeit Daten/Darmstadt")
#In order to use more than one CPU core
if(!require("doParallel")) install.packages("doParallel")
library(doParallel)
registerDoParallel(cores = detectCores(all.tests = FALSE, logical = TRUE))
registerDoParallel(cores = detectCores(all.tests = FALSE, logical = TRUE))
detectCores()
detectCores(logical = FALSE)
#Spatial prediction of urban bicycle traffic volume with machine learning
#Maximilian Weinhold
#------------------------------------------------------------------------
#Model calculations: Support Vector Regression Modell
#In order to create a SVR model with R you will need the package e1071
if(!require("e1071")) install.packages("e1071")
library(e1071)
#In order to make a notification sound to inform the user that calculations are finished
if(!require("beepr")) install.packages("beepr")
library(beepr)
library(tidyverse)
library(sandwich)
library(caret)
#Regarding calculation power see following source: https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#Historically, R has only utilized one processor, which makes it single-threaded.
#Clean up memory
rm(list=ls())
#Source storage location (outside the GitHub Repository)
#Because of file size limitation
#files about 100 MB have to be excluded
setwd("D:/STUDIUM/Münster/7. Semester/Masterarbeit Daten")
load("ValidationSets.rdata")
#Make a simple Test with the support vector regression to show the differences to the OLS regression
svrtest = validation_set[[1]][1:500,]
svrtest$Hour2 = svrtest$Hour^2
svrtest$Hour3 = svrtest$Hour^3
# Create an ols regression model
model1 <- lm(Value ~ Hour + Hour2 + Hour3, data=svrtest)
predict1 <- as.data.frame(predict(model1,svrtest))
predict1$Hour = svrtest$Hour
names(predict1)[1]="Value"
# Create an svm regression model
model2 <- svm(Value ~ Hour, data=svrtest)
predict2 <- as.data.frame(predict(model2, svrtest))
predict2$Hour = svrtest$Hour
names(predict2)[1]="Value"
plot25 = ggplot(svrtest,aes(x = Hour, y = Value)) +
geom_point(size=1.5)+
labs(title = "Vergleich zwischen OLS und Support Vector Regression"
, color = "Methode") +
ggtitle("Vergleich zwischen OLS und Support Vector Regression") +
xlab("Uhrzeit") +
ylab("Fahrradauufkommen") +
theme_bw() +
geom_line(data = predict1, aes(x = Hour, y = Value, color='OLS'), size = 1.5) +
geom_line(data = predict2, aes(x = Hour, y = Value, color='SVR'), size = 1.5)
plot25
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/DataSet Plots")
png(file="plot25.png",width=800, height=800)
plot25
dev.off()
rm(plot25,model1,model2,predict1,predict2,svrtest)
#Now the real Modell
levels(as.factor(validation_set[[1]]$Town))
levels(as.factor(validation_set[[2]]$Town))
levels(as.factor(validation_set[[3]]$Town))
levels(as.factor(validation_set[[4]]$Town))
levels(as.factor(validation_set[[5]]$Town))
length(validation_set)
Evaluation_DF = as.data.frame( matrix(1:length(validation_set)*4, nrow = length(validation_set), ncol = 4) )
names(Evaluation_DF)[1] = "Train_R"
names(Evaluation_DF)[2] = "Train_RMSE"
names(Evaluation_DF)[3] = "Test_R"
names(Evaluation_DF)[4] = "Test_RMSE"
for_start_time <- Sys.time()
for(i in 1:length(validation_set)){
print(i)
testSet = validation_set[[i]]
sets = c(1:length(validation_set))
sets <- sets[!sets %in% i]
trainSet = rbind(validation_set[[ sets[1] ]],validation_set[[ sets[2] ]])
trainSet = rbind(trainSet,validation_set[[ sets[3] ]])
trainSet = rbind(trainSet,validation_set[[ sets[4] ]])
testSet = testSet %>%
mutate(Value = ifelse(Value == 0,1,Value))
trainSet = trainSet %>%
mutate(Value = ifelse(Value == 0,1,Value))
trainSet$X = NULL
testSet$X = NULL
names(testSet)
# Split data to reduce duration of computation
training.samples <- trainSet$Value %>%
createDataPartition(p = 0.005, list = FALSE)
train.data  <- trainSet[training.samples, ]
test.data <- trainSet[-training.samples, ]
#Now do Model calculations
start_time <- Sys.time()
print("Starts to train the modell")
print(start_time)
model <- svm(log(Value) ~ Hour + Months + Weekend + Night + publicHoliday + schoolHoliday +
Wind + CloudCover + Humidity + Rain + Temperature + Cinemas3kmRadius +
ADFC_Index + Area + Inhabitants + Male_Ratio + Distance_to_Center +
ClosestSchool + Schools500mmRadius + Schools2kmRadius + ClosestUniBuild + UniBuild500mmRadius + UniBuild2kmRadius +
ClosestSuperMarket + SuperMarket1kmRadius + ClosestClothesShop + ClothesShop500mmRadius + BusStop250mmRadius + ClothesShop2kmRadius + Signals250mmRadius +
BusStop250mmRadius + UnmCross250mmRadius + BusStop1kmRadius + Tram250mmRadius + Subway250mmRadius + ClosestTrainS + BikeShop3kmRadius +
cycleways + path + secondary + primary + ClosestBridge + young18 + young25 + young30 +
older40 + older60 + Immigrants + PKWs + SignalsRatio, data =  train.data)
end_time <- Sys.time()
print(end_time - start_time)
start_time <- Sys.time()
print("Starts to calclulate test predictions")
print(start_time)
test_predict <- as.data.frame(predict(model, testSet))
end_time <- Sys.time()
print(end_time - start_time)
start_time <- Sys.time()
print("Starts to calclulate train predictions")
print(start_time)
train_predict <- as.data.frame(predict(model, train.data))
end_time <- Sys.time()
print(end_time - start_time)
Evaluation_DF$Test_RMSE[i] = sqrt(mean((testSet$Value - exp(test_predict[,1]))^2))
Evaluation_DF$Train_RMSE[i] = sqrt(mean((train.data$Value - exp(train_predict[,1]))^2))
#cor(test_predict,testSet$Value) ^ 2
#cor(train_predict,trainSet$Value) ^ 2
Evaluation_DF$Test_R[i]= postResample(exp(test_predict), testSet$Value)[2]
Evaluation_DF$Train_R[i]= postResample(exp(train_predict), train.data$Value)[2]
#vcovHAC(model)
}
for_end_time <- Sys.time()
print("The hole process took:")
print(for_end_time - for_start_time)
mean(Evaluation_DF$Train_R)
mean(Evaluation_DF$Train_RMSE)
mean(Evaluation_DF$Test_R)
mean(Evaluation_DF$Test_RMSE)
Evaluation_DF[6,]=c(mean(Evaluation_DF$Train_R),mean(Evaluation_DF$Train_RMSE),mean(Evaluation_DF$Test_R),mean(Evaluation_DF$Test_RMSE))
Evaluation_DF$Sets=c("1","2","3","4","5","Mean")
Evaluation_DF <- Evaluation_DF[, c(5,1,2,3,4)]
beep("fanfare")
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/ValidationResults")
write.csv(BikeData,"Modell2_SVR.csv")
write.csv(Evaluation_DF,"Modell2_SVR.csv")
Evaluation_DF
save(model,file="ValidationSets.rdata")
save(model,file="Modell2_SVR.rdata")
#Spatial prediction of urban bicycle traffic volume with machine learning
#Maximilian Weinhold
#------------------------------------------------------------------------
#Model calculations: OLS Regression Modell
library(tidyverse)
library(sandwich)
library(caret)
#Regarding calculation power see following source: https://nceas.github.io/oss-lessons/parallel-computing-in-r/parallel-computing-in-r.html
#Historically, R has only utilized one processor, which makes it single-threaded.
#Clean up memory
rm(list=ls())
#Source storage location (outside the GitHub Repository)
#Because of file size limitation
#files about 100 MB have to be excluded
setwd("D:/STUDIUM/Münster/7. Semester/Masterarbeit Daten")
load("ValidationSets.rdata")
names(validation_set[[1]])
levels(as.factor(validation_set[[1]]$Town))
levels(as.factor(validation_set[[2]]$Town))
levels(as.factor(validation_set[[3]]$Town))
levels(as.factor(validation_set[[4]]$Town))
levels(as.factor(validation_set[[5]]$Town))
length(validation_set)
Evaluation_DF = as.data.frame( matrix(1:length(validation_set)*4, nrow = length(validation_set), ncol = 4) )
names(Evaluation_DF)[1] = "Train_R"
names(Evaluation_DF)[2] = "Train_RMSE"
names(Evaluation_DF)[3] = "Test_R"
names(Evaluation_DF)[4] = "Test_RMSE"
for_start_time <- Sys.time()
for(i in 1:length(validation_set)){
print(i)
testSet = validation_set[[i]]
sets = c(1:length(validation_set))
sets <- sets[!sets %in% i]
trainSet = rbind(validation_set[[ sets[1] ]],validation_set[[ sets[2] ]])
trainSet = rbind(trainSet,validation_set[[ sets[3] ]])
trainSet = rbind(trainSet,validation_set[[ sets[4] ]])
testSet = testSet %>%
mutate(Value = ifelse(Value == 0,1,Value))
trainSet = trainSet %>%
mutate(Value = ifelse(Value == 0,1,Value))
trainSet$X = NULL
testSet$X = NULL
names(testSet)
#Now do Model calculations
model <- lm(log(Value) ~ Hour + Months + Weekend + Night + publicHoliday + schoolHoliday +
Wind + CloudCover + Humidity + Rain + Temperature + Cinemas3kmRadius +
ADFC_Index + Area + Inhabitants + Male_Ratio + Distance_to_Center +
ClosestSchool + Schools500mmRadius + Schools2kmRadius + ClosestUniBuild + UniBuild500mmRadius + UniBuild2kmRadius +
ClosestSuperMarket + SuperMarket1kmRadius + ClosestClothesShop + ClothesShop500mmRadius + BusStop250mmRadius + ClothesShop2kmRadius + Signals250mmRadius +
BusStop250mmRadius + UnmCross250mmRadius + BusStop1kmRadius + Tram250mmRadius + Subway250mmRadius + ClosestTrainS + BikeShop3kmRadius +
cycleways + path + secondary + primary + ClosestBridge + young18 + young25 + young30 +
older40 + older60 + Immigrants + PKWs +
Rain2 + Temperature2 + Inhabitants2 + ADFC_Index2 + UniBuild500mmRadius2 + ClothesShop500mmRadius2 +
ClosestTrainS2 + ClosestBridge2 + young302 + PKWs2 + Rain3 +
Inhabitants3 + UniBuild500mmRadius3 + ClothesShop500mmRadius3 + ClosestTrainS3 + SignalsRatio, data = trainSet)
summary(model)
test_predict <- model %>% predict(testSet)
train_predict <- model %>% predict(trainSet)
Evaluation_DF$Test_RMSE[i] = sqrt(mean((testSet$Value - test_predict)^2))
Evaluation_DF$Train_RMSE[i] = sqrt(mean((trainSet$Value - train_predict)^2))
#cor(test_predict,testSet$Value) ^ 2
#cor(train_predict,trainSet$Value) ^ 2
Evaluation_DF$Test_R[i]= postResample(test_predict, testSet$Value)[2]
Evaluation_DF$Train_R[i]= postResample(train_predict, trainSet$Value)[2]
#vcovHAC(model)
}
for_end_time <- Sys.time()
print("The hole process took:")
print(for_end_time - for_start_time)
mean(Evaluation_DF$Train_R)
mean(Evaluation_DF$Train_RMSE)
mean(Evaluation_DF$Test_R)
mean(Evaluation_DF$Test_RMSE)
Evaluation_DF[6,]=c(mean(Evaluation_DF$Train_R),mean(Evaluation_DF$Train_RMSE),mean(Evaluation_DF$Test_R),mean(Evaluation_DF$Test_RMSE))
Evaluation_DF$Sets=c("1","2","3","4","5","Mean")
Evaluation_DF <- Evaluation_DF[, c(5,1,2,3,4)]
beep("fanfare")
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/ValidationResults")
write.csv(Evaluation_DF,"Modell1_OLS.csv")
save(model,file="Modell1_OLS.rdata")
beep()
beep("coin")
beep("complete")
beep("treasure")
beep("ready")
beep("shotgun")
beep("mario")
beep("wilhelm")
beep("facebook")
beep("mario")
beep("fanfare")
beep("mario")
#Spatial prediction of urban bicycle traffic volume with machine learning
#Maximilian Weinhold
#------------------------------------------------------------------------
#Model Map Projection
#In order to make a notification sound to inform the user that calculations are finished
if(!require("beepr")) install.packages("beepr")
library(beepr)
library(tidyverse)
#Clean up memory
rm(list=ls())
#calculated models are her:
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/ValidationResults")
load("Modell1_OLS.rdata")
#Clean up memory
rm(list=ls())
#Spatial prediction of urban bicycle traffic volume with machine learning
#Maximilian Weinhold
#------------------------------------------------------------------------
#Model Map Projection
#In order to make a notification sound to inform the user that calculations are finished
if(!require("beepr")) install.packages("beepr")
library(beepr)
library(tidyverse)
#Clean up memory
rm(list=ls())
#calculated models are her:
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/ValidationResults")
load("Modell1_OLS.rdata")
summary(model)
#Spatial prediction of urban bicycle traffic volume with machine learning
#Maximilian Weinhold
#------------------------------------------------------------------------
#Model Map Projection
if(!require("beepr")) install.packages("beepr")
if(!require("osmdata")) install.packages("osmdata")
if(!require("tidyverse")) install.packages("tidyverse")
if(!require("sf")) install.packages("sf")
if(!require("ggmap")) install.packages("ggmap")
#load packages
library(beepr)
library(tidyverse)
library(osmdata)
library(sf)
library(ggmap)
#Clean up memory
rm(list=ls())
#calculated models are her:
setwd("C:/Users/MaxWe/Documents/GitHub/Masterthesis_BikeTrafficForecast/ValidationResults")
load("Modell1_OLS.rdata")
summary(model)
city = "Hamburg"
#building the query
q <- getbb(city) %>%
opq() %>%
add_osm_feature("amenity", "cinema")
str(q) #query structure
cinema <- osmdata_sf(q)
#our background map
mad_map <- get_map(getbb("Madrid"), maptype = "toner-background")
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
city = "Hamburg"
#building the query
q <- getbb(city) %>%
opq() %>%
add_osm_feature("amenity", "cinema")
str(q) #query structure
cinema <- osmdata_sf(q)
#our background map
mad_map <- get_map(getbb(city), maptype = "toner-background")
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
city = "Münster"
#building the query
q <- getbb(city) %>%
opq() %>%
add_osm_feature("amenity", "cinema")
str(q) #query structure
cinema <- osmdata_sf(q)
#our background map
mad_map <- get_map(getbb(city), maptype = "toner-background")
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
#our background map
myLocation<-c(7.597514856738869,51.94573812395569,   7.652382675482133,51.9756143280805)
mad_map <- get_nmap(bbox=myLocation, maptype="toner-background")
mad_map <- get_map(bbox=myLocation, maptype="toner-background")
#get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=7)
mad_map <- get_stamenmap(bbox=myLocation, maptype="toner-background")
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
#get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=7)
mad_map <- get_stamenmap(bbox=myLocation, maptype="toner-background", zoom=7)
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
#get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=7)
mad_map <- get_stamenmap(bbox=myLocation, maptype="toner-background", zoom=10)
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
#get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=7)
mad_map <- get_stamenmap(bbox=myLocation, maptype="toner-background", zoom=16)
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
#get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=7)
mad_map <- get_stamenmap(bbox=myLocation, maptype="terrain-background", zoom=14)
#final map
ggmap(mad_map)+
geom_sf(data = cinema$osm_points,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 4,
shape = 21)+
labs(x = "", y = "")
city = "Münster"
#building the query
q <- getbb(city) %>%
opq() %>%
add_osm_feature("highway")
str(q) #query structure
streets <- osmdata_sf(q)
streets
#final map
ggmap(mad_map)+
geom_sf(data = streets$osm_lines,
inherit.aes = FALSE,
colour = "#238443",
fill = "#004529",
alpha = .5,
size = 1
)+
labs(x = "", y = "")
